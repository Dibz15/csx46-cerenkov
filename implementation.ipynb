{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import crossValidate\n",
    "import performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eced2fd0db89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomRows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfoldsCollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossValidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetKfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'osu18_groups.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnreps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/csx46-cerenkov/crossValidate.py\u001b[0m in \u001b[0;36mgetKfolds\u001b[0;34m(dataFile, groupsFile, k, nreps)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetKfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroupsFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# read data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;31m#dataDF = pandas.read_csv(dataFile, sep='\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#Drop any rows that have NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv('osu18_cerenkov_feat_mat.tsv', sep='\\t')\n",
    "\n",
    "test_size = 0.2\n",
    "randomRows = df.sample(frac=test_size).index\n",
    "\n",
    "testData = df.iloc[randomRows,:]\n",
    "\n",
    "df = df.drop(randomRows)\n",
    "k = 3\n",
    "foldsCollection = crossValidate.getKfolds(df, 'osu18_groups.tsv', k, nreps=1)\n",
    "\n",
    "models = []\n",
    "for foldGroup in foldsCollection:\n",
    "    foldList = foldGroup[0]\n",
    "    labelList = foldGroup[1]\n",
    "    \n",
    "    avg_auc = 0\n",
    "    for idx in range(len(foldList)):\n",
    "        testX = foldList[idx]\n",
    "        testY = labelList[idx]\n",
    "        print('Fold {}'.format(idx))\n",
    "        print('Test Size: {}'.format(testX.shape[0]))\n",
    "        \n",
    "        #trainX = crossValidate.getRemainder(foldList, testX)\n",
    "        #trainY = crossValidate.getRemainder(labelList, testY)\n",
    "        \n",
    "        #print('Train Size: {}'.format(trainX.shape[0]))\n",
    "        \n",
    "        trainX = np.empty(shape=[0, testX.shape[1]])\n",
    "        trainY = np.empty(shape=[0,])\n",
    "        \n",
    "        for j in range(len(foldList)):\n",
    "            if j != idx:\n",
    "                trainX = np.concatenate((trainX, foldList[j]), axis=0)\n",
    "                trainY = np.concatenate((trainY, labelList[j]), axis=0)\n",
    "                \n",
    "        \n",
    "        X_smt = trainX\n",
    "        y_smt = trainY\n",
    "        \n",
    "        _RANDOM_STATE = 1337\n",
    "        # class_balance = len(y) / sum(y) - 1  # n_negative / n_positive\n",
    "        rare_event_rate = sum(y_smt) / len(y_smt)\n",
    "\n",
    "        param_dist = dict(max_depth=7,\n",
    "                    learning_rate=0.1,\n",
    "                    n_estimators=40,\n",
    "                    gamma=10,\n",
    "                    scale_pos_weight=1,\n",
    "                    base_score=rare_event_rate,\n",
    "                    subsample=1,\n",
    "                    objective= 'binary:logistic' )\n",
    "\n",
    "        #param_dist = { 'objective':'binary:logistic', 'n_estimators': 2 }\n",
    "\n",
    "\n",
    "        clf = xgb.XGBClassifier(**param_dist, booster='gbtree', n_jobs=-1, random_state=_RANDOM_STATE)\n",
    "\n",
    "        clf.fit( X_smt, y_smt,\n",
    "                eval_set=[(X_smt, y_smt), (testX, testY)],\n",
    "                eval_metric='logloss',\n",
    "                verbose=False)\n",
    "\n",
    "        preds = clf.predict(testX)\n",
    "        curr_auc = performance.getAUC(testY, preds)\n",
    "        print('Current fold AUC: {}'.format(curr_auc))\n",
    "        print('Current fold accuracy: {}'.format(performance.getAccuracy(testY, preds)))\n",
    "        avg_auc += curr_auc\n",
    "        \n",
    "        models.append(clf)\n",
    "        \n",
    "    avg_auc /= k\n",
    "    print('Average K-Fold AUC for all folds: {}'.format(avg_auc))\n",
    "\n",
    "def getEnsemblePredictions(models, testX):\n",
    "    predictions = np.zeros(shape=[testX.shape[0], 1])\n",
    "    for model in models:\n",
    "        preds = model.predict(testX)\n",
    "        #Sum up all predictions for averaging\n",
    "        predictions += preds\n",
    "\n",
    "    #Average the predictions\n",
    "    predictions = predictions / len(models)\n",
    "\n",
    "    #Force the predictions to a binary value for testing\n",
    "    predictions = [1 if val >= 0.5 else 0 for val in predictions]\n",
    "    return predictions\n",
    "\n",
    "testData = testData.drop(testData.query('label != 0 & label != 1').index)\n",
    "del testData['name']\n",
    "testData = testData.astype(float)\n",
    "labels = df['label']\n",
    "del df['label']\n",
    "labels = labels.astype(int)\n",
    "\n",
    "testX = testData\n",
    "testY = labels\n",
    "\n",
    "ensembledPredictions = getEnsemblePredictions(models, testX)\n",
    "\n",
    "print('Final Ensemble Predictions')\n",
    "performance.printStats(testY, ensembledPredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrainDf = df[:10000]\\ntestDf = df[10000:]\\n\\n\\ndtrain = xgb.DMatrix(trainDf, label=labels[:10000])\\ndtest = xgb.DMatrix(testDf, label=labels[10000:])\\n\\n\\nevallist = [(dtest, 'eval'), (dtrain, 'train')]\\n\\n\\n# param_dist = dict(max_depth=[7],\\n#                   learning_rate=[0.1],\\n#                   n_estimators=[40], \\n#                   gamma=[10],\\n#                   scale_pos_weight=[1],\\n#                   base_score=[rare_event_rate],\\n#                   subsample=[1])\\n\\nparam = dict(max_depth=7,\\n            learning_rate=0.1,\\n            n_estimators=10,\\n            gamma=10,\\n            scale_pos_weight=1,\\n            base_score=0.5,\\n            subsample=1)\\n\\nnum_round = 20\\n\\nbst = xgb.train(param, dtrain, num_round, evallist)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 10816, 1: 661})\n",
      "Counter({0: 661, 1: 661})\n"
     ]
    }
   ],
   "source": [
    "split = 5000\n",
    "\n",
    "X = df\n",
    "y = labels\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(Counter(trainY))\n",
    "\n",
    "#smt = SMOTETomek(sampling_strategy='auto')\n",
    "smt = RandomUnderSampler(sampling_strategy='auto')\n",
    "#smt = TomekLinks(sampling_strategy='auto')\n",
    "#smt = ClusterCentroids(sampling_strategy='auto')\n",
    "#enn = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=7)\n",
    "#smote = SMOTE(sampling_strategy='auto', k_neighbors=3)\n",
    "#smt = SMOTEENN(sampling_strategy='auto', smote=smote, enn=None)\n",
    "\n",
    "X_smt, y_smt = smt.fit_resample(trainX, trainY)\n",
    "\n",
    "print(Counter(y_smt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65347\tvalidation_1-logloss:0.66155\n",
      "[1]\tvalidation_0-logloss:0.62318\tvalidation_1-logloss:0.63667\n",
      "[2]\tvalidation_0-logloss:0.60094\tvalidation_1-logloss:0.61960\n",
      "[3]\tvalidation_0-logloss:0.57827\tvalidation_1-logloss:0.60174\n",
      "[4]\tvalidation_0-logloss:0.55796\tvalidation_1-logloss:0.58671\n",
      "[5]\tvalidation_0-logloss:0.53929\tvalidation_1-logloss:0.57369\n",
      "[6]\tvalidation_0-logloss:0.52831\tvalidation_1-logloss:0.56744\n",
      "[7]\tvalidation_0-logloss:0.51772\tvalidation_1-logloss:0.56042\n",
      "[8]\tvalidation_0-logloss:0.50701\tvalidation_1-logloss:0.55281\n",
      "[9]\tvalidation_0-logloss:0.49522\tvalidation_1-logloss:0.54283\n",
      "[10]\tvalidation_0-logloss:0.48798\tvalidation_1-logloss:0.53702\n",
      "[11]\tvalidation_0-logloss:0.48045\tvalidation_1-logloss:0.53441\n",
      "[12]\tvalidation_0-logloss:0.47124\tvalidation_1-logloss:0.52729\n",
      "[13]\tvalidation_0-logloss:0.46861\tvalidation_1-logloss:0.52466\n",
      "[14]\tvalidation_0-logloss:0.46274\tvalidation_1-logloss:0.51935\n",
      "[15]\tvalidation_0-logloss:0.45586\tvalidation_1-logloss:0.51512\n",
      "[16]\tvalidation_0-logloss:0.45321\tvalidation_1-logloss:0.51428\n",
      "[17]\tvalidation_0-logloss:0.44778\tvalidation_1-logloss:0.51081\n",
      "[18]\tvalidation_0-logloss:0.44453\tvalidation_1-logloss:0.50887\n",
      "[19]\tvalidation_0-logloss:0.43920\tvalidation_1-logloss:0.50666\n",
      "[20]\tvalidation_0-logloss:0.43580\tvalidation_1-logloss:0.50494\n",
      "[21]\tvalidation_0-logloss:0.43429\tvalidation_1-logloss:0.50513\n",
      "[22]\tvalidation_0-logloss:0.43106\tvalidation_1-logloss:0.50326\n",
      "[23]\tvalidation_0-logloss:0.42849\tvalidation_1-logloss:0.50116\n",
      "[24]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49864\n",
      "[25]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49875\n",
      "[26]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49885\n",
      "[27]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49894\n",
      "[28]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49903\n",
      "[29]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49910\n",
      "[30]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49917\n",
      "[31]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49923\n",
      "[32]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49928\n",
      "[33]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49933\n",
      "[34]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49938\n",
      "[35]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49941\n",
      "[36]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49945\n",
      "[37]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49948\n",
      "[38]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49951\n",
      "[39]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49954\n",
      "[40]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49956\n",
      "[41]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49958\n",
      "[42]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49960\n",
      "[43]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49962\n",
      "[44]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49963\n",
      "[45]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49965\n",
      "[46]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49966\n",
      "[47]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49967\n",
      "[48]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49968\n",
      "[49]\tvalidation_0-logloss:0.42616\tvalidation_1-logloss:0.49969\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "#cross_val_score(clf, X, y, cv=cv)\n",
    "\n",
    "evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Performance Stats ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      2691\n",
      "           1       0.23      0.78      0.36       179\n",
      "\n",
      "    accuracy                           0.82      2870\n",
      "   macro avg       0.61      0.80      0.63      2870\n",
      "weighted avg       0.94      0.82      0.86      2870\n",
      "\n",
      "\n",
      "Sensitivity (ability to correctly predict true): 0.7821229050279329\n",
      "Specificity (ability to correctly predict false): 0.8272017837235228\n",
      "Informedness (probability of informed decision): 0.6093246887514558\n",
      "Accuracy: 0.824390243902439\n",
      "ROC AUC: 0.8046623443757278\n",
      "Confusion matrix:\n",
      " [[2226  465]\n",
      " [  39  140]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_round=25\n",
    "preds = clf.predict(testX)\n",
    "performance.printStats(testY, preds)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "conf_mat = performance.getConfusionMatrix(testY, preds)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
